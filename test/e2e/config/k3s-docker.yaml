---
# E2E test scenario using local dev images and manifests built from the source tree for following providers:
# - cluster-api
# - bootstrap k3s
# - control-plane k3s
# - docker
images:
  # Use local dev images built source tree;
  - name: ghcr.io/k3s-io/cluster-api-k3s/controlplane-controller:dev
    loadBehavior: mustLoad
  - name: ghcr.io/k3s-io/cluster-api-k3s/bootstrap-controller:dev
    loadBehavior: mustLoad

providers:
  - name: cluster-api
    type: CoreProvider
    versions:
      - name: v1.8.1
        value: https://github.com/kubernetes-sigs/cluster-api/releases/download/v1.8.1/core-components.yaml
        type: url
        contract: v1beta1
        files:
          - sourcePath: "../data/shared/v1beta1/metadata.yaml"
        replacements:
          - old: "imagePullPolicy: Always"
            new: "imagePullPolicy: IfNotPresent"
  - name: docker
    type: InfrastructureProvider
    versions:
      # Will use the latest version defined in ../data/shared/v1beta1/metadata.yaml
      # to init the management cluster
      - name: v1.8.1 # used during e2e-test
        value: https://github.com/kubernetes-sigs/cluster-api/releases/download/v1.8.1/infrastructure-components-development.yaml
        type: url
        contract: v1beta1
        files:
          - sourcePath: "../data/shared/v1beta1/metadata.yaml"
        replacements:
          - old: "imagePullPolicy: Always"
            new: "imagePullPolicy: IfNotPresent"
    files:
      - sourcePath: "../data/infrastructure-docker/cluster-template.yaml"
      - sourcePath: "../data/infrastructure-docker/cluster-template-kcp-remediation.yaml"
      - sourcePath: "../data/infrastructure-docker/cluster-template-md-remediation.yaml"
      - sourcePath: "../data/infrastructure-docker/cluster-template-v1beta1.yaml"
      - sourcePath: "../data/infrastructure-docker/cluster-template-topology.yaml"
      - sourcePath: "../data/infrastructure-docker/clusterclass-k3s.yaml"
  - name: k3s
    type: BootstrapProvider
    versions:
      # Older release is added for k3s provider upgrading test (clusterctl_upgrade_test),
      # all other tests will use the k3s build from source
      # to init the management cluster.
      - name: "v0.2.0"
        value: "https://github.com/k3s-io/cluster-api-k3s/releases/download/v0.2.0/bootstrap-components.yaml"
        type: "url"
        contract: v1beta1
        files:
          - sourcePath: "../data/shared/k3s/v0.2/metadata.yaml"
            targetName: "metadata.yaml"
      # By default, will only use the latest version defined in
      # ${ProjectRoot}/metadata.yaml (this one) to init the management cluster
      # this version should be updated when ${ProjectRoot}/metadata.yaml
      # is modified
      - name: v0.2.99 # next; use manifest from source files
        value: "../../../bootstrap/config/default"
        files:
          - sourcePath: "../../../metadata.yaml"
            targetName: "metadata.yaml"
  - name: k3s
    type: ControlPlaneProvider
    versions:
      - name: "v0.2.0"
        value: "https://github.com/k3s-io/cluster-api-k3s/releases/download/v0.2.0/control-plane-components.yaml"
        type: "url"
        contract: v1beta1
        files:
          - sourcePath: "../data/shared/k3s/v0.2/metadata.yaml"
            targetName: "metadata.yaml"
      - name: v0.2.99 # next; use manifest from source files
        value: "../../../controlplane/config/default"
        files:
          - sourcePath: "../../../metadata.yaml"
            targetName: "metadata.yaml"

variables:
  KUBERNETES_VERSION_MANAGEMENT: "v1.30.0"
  KUBERNETES_VERSION: "v1.30.2+k3s2"
  KUBERNETES_VERSION_UPGRADE_TO: "v1.30.3+k3s1"
  IP_FAMILY: "IPv4"
  KIND_IMAGE_VERSION: "v1.30.0"
  # Used during clusterctl upgrade test
  CAPI_CORE_VERSION: "1.8.1"
  K3S_CAPI_CURRENT_VERSION: "0.2.99"
  # Enabling the feature flags by setting the env variables.
  CLUSTER_TOPOLOGY: "true"
  EXP_MACHINE_POOL: "true"

intervals:
  # The array is defined as [timeout, polling interval]
  # copied from https://github.com/kubernetes-sigs/cluster-api/blob/main/test/e2e/config/docker.yaml
  default/wait-controllers: ["3m", "10s"]
  default/wait-cluster: ["5m", "10s"]
  default/wait-control-plane: ["10m", "10s"]
  default/wait-worker-nodes: ["10m", "10s"]
  default/wait-machine-pool-nodes: ["10m", "10s"]
  default/wait-delete-cluster: ["3m", "10s"]
  default/wait-machine-upgrade: ["30m", "10s"]
  default/wait-machine-pool-upgrade: ["30m", "10s"]
  default/wait-nodes-ready: ["10m", "10s"]
  default/wait-machine-remediation: ["5m", "10s"]
  default/wait-autoscaler: ["5m", "10s"]
  node-drain/wait-deployment-available: ["3m", "10s"]
  node-drain/wait-control-plane: ["15m", "10s"]
  node-drain/wait-machine-deleted: ["2m", "10s"]
  kcp-remediation/wait-machines: ["5m", "10s"]
  kcp-remediation/check-machines-stable: ["30s", "5s"]
  kcp-remediation/wait-machine-provisioned: ["5m", "10s"]
  #  Giving a bit more time during scale tests, we analyze independently if everything works quickly enough.
  scale/wait-cluster: ["10m", "10s"]
  scale/wait-control-plane: ["20m", "10s"]
  scale/wait-worker-nodes: ["20m", "10s"]