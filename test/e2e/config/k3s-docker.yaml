---
# E2E test scenario using local dev images and manifests built from the source tree for following providers:
# - cluster-api
# - bootstrap k3s
# - control-plane k3s
# - docker
images:
  # Use local dev images built source tree;
  - name: ghcr.io/k3s-io/cluster-api-k3s/controlplane-controller:dev
    loadBehavior: mustLoad
  - name: ghcr.io/k3s-io/cluster-api-k3s/bootstrap-controller:dev
    loadBehavior: mustLoad

providers:
  - name: cluster-api
    type: CoreProvider
    versions:
      - name: v1.7.2
        value: https://github.com/kubernetes-sigs/cluster-api/releases/download/v1.7.2/core-components.yaml
        type: url
        files:
          - sourcePath: "../data/shared/v1beta1/metadata.yaml"
        replacements:
          - old: "imagePullPolicy: Always"
            new: "imagePullPolicy: IfNotPresent"
  - name: docker
    type: InfrastructureProvider
    versions:
      # By default, will use the latest version defined in ../data/shared/v1beta1/metadata.yaml
      # to init the management cluster
      - name: v1.7.2 # used during e2e-test
        value: https://github.com/kubernetes-sigs/cluster-api/releases/download/v1.7.2/infrastructure-components-development.yaml
        type: url
        files:
          - sourcePath: "../data/shared/v1beta1/metadata.yaml"
        replacements:
          - old: "imagePullPolicy: Always"
            new: "imagePullPolicy: IfNotPresent"
      
      # Add v1.8.99 to support tilt (not presented in ../data/shared/v1beta1/metadata.yaml)
      # when bootstrapping with tilt, it will use
      # the defaultProviderVersion in https://github.com/kubernetes-sigs/cluster-api/blob/main/hack/tools/internal/tilt-prepare/main.go as 
      # default version for docker infrastructure provider
      # name here should match defaultProviderVersion
      - name: v1.8.99 # next; use manifest from source files
        value: https://github.com/kubernetes-sigs/cluster-api/releases/latest/download/infrastructure-components-development.yaml
        type: url
        files:
          - sourcePath: "../data/shared/v1beta1/metadata.yaml"
        replacements:
          - old: "imagePullPolicy: Always"
            new: "imagePullPolicy: IfNotPresent"
    files:
      - sourcePath: "../data/infrastructure-docker/cluster-template.yaml"
      - sourcePath: "../data/infrastructure-docker/cluster-template-kcp-remediation.yaml"
      - sourcePath: "../data/infrastructure-docker/cluster-template-md-remediation.yaml"
      - sourcePath: "../data/infrastructure-docker/cluster-template-v1beta1.yaml"
      - sourcePath: "../data/infrastructure-docker/cluster-template-topology.yaml"
      - sourcePath: "../data/infrastructure-docker/clusterclass-k3s.yaml"
  - name: k3s
    type: BootstrapProvider
    versions:
      # Could add older release version for upgrading test, but
      # by default, will only use the latest version defined in
      # ${ProjectRoot}/metadata.yaml to init the management cluster
      # this version should be updated when ${ProjectRoot}/metadata.yaml
      # is modified
      - name: v0.1.99 # next; use manifest from source files
        value: "../../../bootstrap/config/default"
    files:
      - sourcePath: "../../../metadata.yaml"
        targetName: "metadata.yaml"
  - name: k3s
    type: ControlPlaneProvider
    versions:
      - name: v0.1.99 # next; use manifest from source files
        value: "../../../controlplane/config/default"
    files:
      - sourcePath: "../../../metadata.yaml"
        targetName: "metadata.yaml"

variables:
  KUBERNETES_VERSION_MANAGEMENT: "v1.28.0"
  KUBERNETES_VERSION: "v1.28.6+k3s2"
  KUBERNETES_VERSION_UPGRADE_TO: "v1.28.7+k3s1"
  IP_FAMILY: "IPv4"
  KIND_IMAGE_VERSION: "v1.28.0"
  # Enabling the feature flags by setting the env variables.
  CLUSTER_TOPOLOGY: "true"
  EXP_MACHINE_POOL: "true"

intervals:
  # The array is defined as [timeout, polling interval]
  # copied from https://github.com/kubernetes-sigs/cluster-api/blob/main/test/e2e/config/docker.yaml
  default/wait-controllers: ["3m", "10s"]
  default/wait-cluster: ["5m", "10s"]
  default/wait-control-plane: ["10m", "10s"]
  default/wait-worker-nodes: ["10m", "10s"]
  default/wait-machine-pool-nodes: ["10m", "10s"]
  default/wait-delete-cluster: ["3m", "10s"]
  default/wait-machine-upgrade: ["30m", "10s"]
  default/wait-machine-pool-upgrade: ["30m", "10s"]
  default/wait-nodes-ready: ["10m", "10s"]
  default/wait-machine-remediation: ["5m", "10s"]
  default/wait-autoscaler: ["5m", "10s"]
  node-drain/wait-deployment-available: ["3m", "10s"]
  node-drain/wait-control-plane: ["15m", "10s"]
  node-drain/wait-machine-deleted: ["2m", "10s"]
  kcp-remediation/wait-machines: ["5m", "10s"]
  kcp-remediation/check-machines-stable: ["30s", "5s"]
  kcp-remediation/wait-machine-provisioned: ["5m", "10s"]
  #  Giving a bit more time during scale tests, we analyze independently if everything works quickly enough.
  scale/wait-cluster: ["10m", "10s"]
  scale/wait-control-plane: ["20m", "10s"]
  scale/wait-worker-nodes: ["20m", "10s"]